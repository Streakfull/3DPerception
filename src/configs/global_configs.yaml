# This file contains all the configuration our different project components
# Add configurations as needed

training:
  name: vaeKosmoBa2a
  description: plzWork2
  experiment_id: Chairs256ConvLinearMUCalc # None | A unique id identifying the experiment folder
  #experiment_id: None
  extra_notes: none
  logs_dir: logs
  is_train: true
  device: cuda:0
  batch_size: 16
  num_workers: 16
  test_size: 0.1
  n_epochs: 50000
  append_loss_every: 50
  print_every: 50
  validate_every: 1480
  save_every: 1480
  save_every_nepochs: 2
  start_epoch: 0
  start_iteration: 0
  visualize_every: 200
  apply_metrics_every: 1480
  load_ckpt: True
  #ckpt_path: logs/VaeTry2/8*8*8**FullTrain/2024_05_21_03_41_13/checkpoints/epoch-74.ckpt
  #ckpt_path: logs/pvqVAE/pvqVAE-Train/2024_05_26_02_46_01/checkpoints/epoch-114.ckpt # PatchedPVQVAE
  #ckpt_path: logs/pvqVAE/pvqVAE-RandTransformerTrain2/2024_05_27_03_34_37/checkpoints/epoch-500.ckpt #16bs tran
  #ckpt_path: logs/pvqVAE/transformerTrain/2024_05_28_11_35_43/checkpoints/epoch-latest.ckpt #8bs Trans
  #ckpt_path: logs/DisnDatasetTraining/2024_05_09_03_55_02/checkpoints/epoch-116.ckpt #Auto Encoder
  ckpt_path: logs/GlobalPVQVAE/FullTrain/2024_06_03_12_37_19/checkpoints/epoch-latest.ckpt #Global
  #ckpt_path: logs/imp_experiments/2024_05_09_03_55_02/checkpoints/epoch-124.ckpt
  ckpt_path: logs/VAEPlzWork/128x10e-4x1e-4/2024_06_02_23_35_18/checkpoints/epoch-latest.ckpt
  ckpt_path: logs/vaeKosmoBa2a/Cars256KL/2024_06_24_19_39_11/checkpoints/epoch-14.ckpt
  ckpt_path: logs/vaeKosmoBa2a/Chairs256ConvLinear/2024_06_24_22_16_25/checkpoints/epoch-44.ckpt
  use_scheduler: True
  apply_metrics_batch_count: 5 # number of batches to apply additional metrics on
#2024_05_16_20_23_24 id
dataset:
  dataset_field: shape_net_v3_sdf
  path: ../../datasets/shapenet_orig/ShapeNetCore.v2  # For local testing without downloading shape => change to local_raw_dataset/ShapeNet
    # Can be overriden by dataset specific path
  overfit_size: 1
  split: train # train | valid | test
  is_overfit: False

  shape_net_vox:
    class_filepath: src/datasets/shape_net/shape_net_vox.py
    class: ShapeNetVox
    category: airplane
    path: src/local_raw_dataset/ShapeNet/ShapeNetVox32

  shape_net_points:
    class_filepath: src/datasets/shape_net/shape_net_points.py
    class: ShapeNetPoints
    category: airplane
    path: src/raw_dataset/ShapeNet/ShapeNetPointClouds
  
  shape_net_sdf:
    category: chair
    path: src/raw_dataset/ShapeNetV2/sdf_064
    class_filepath: datasets/shape_net/shape_net_sdf.py
    class: ShapeNetSDF

  shape_net_v2_sdf:
    class_filepath: src/datasets/shape_net/shape_net_v2_sdf.py
    class: ShapeNetV2SDF
    category: chair
    #path:  ../../datasets/shapenet_orig/ShapeNetCore.v2
    path: src/raw_dataset/shapenet_orig
  
  shape_net_v3_sdf:
    class_filepath: src/datasets/shape_net/shape_net_v3_sdf.py
    class: ShapeNetV3SDF
    category: chair
    path: src/raw_dataset/ShapeNetDISN/SDF_v1_64
  
  shape_net_code:
    class_filepath: src/datasets/shape_net/shape_net_code.py
    class: ShapeNetCode
    category: chair
    path: src/raw_dataset/ShapeNetDISN/SDF_v1_64

model:
  model_field:  vae
  dummy_classifier:
    model_filepath: models/dummy_classifier.py
    model_class: DummyClassifier
    lr: 0.01
    criterion: CE
    scheduler_step_size: 25
    scheduler_gamma: 0.5
    dummy_network:
      kernel_size: 3
      padding: 1
  
  auto_encoder:
    model_filepath: src/models/auto_encoder.py
    model_class: AutoEncoder
    metrics: iou,chamferDistance   # None | iou | chamferDistance
    lr: 0.001
    losses: None
    criterion: MSE
    scheduler_step_size: 300
    scheduler_gamma: 0.5
    weight_init: None    #None | normal | xavier | xavier_uniform | kaiming | orthogonal
    gain: 0.02 
    auto_encoder_networks:
      in_channels: 1
      out_channels: 64
      ch_mult: [1, 2, 2, 4]
      num_res_blocks: 1
      attn_resolutions: [8]
      dropout: 0.0
      resamp_with_conv: true
      resolution: 64
  
  vae:
    model_filepath: src/models/vae.py
    model_class: VAE
    metrics: iou,chamferDistance   # None | iou | chamferDistance
    losses: "l1,kl,kl_weight" #additional loss names
    lr: 4.5e-6
    criterion: L1
    base_kl_weight: 1.4e-3
    reconst_weight: 1.0e-4 #1
    scheduler_step_size: 30
    scheduler_gamma: 0.5
    cycle_iter: 15000
    stop_cycle_count: 60000
   #stop_cycle_count: 1
    weight_init: normal    #None | normal | xavier | xavier_uniform | kaiming | orthogonal
    gain: 0.02
    auto_encoder_networks:
      in_channels: 1
      out_channels: 256
      ch_mult: [1, 2, 2, 4]
      num_res_blocks: 1
      attn_resolutions: [8]
      dropout: 0.0
      resamp_with_conv: true
      resolution: 64

  vae3d:
    vae:
    model_filepath: src/models/vae3D.py
    model_class: VAE3D
    metrics: iou,chamferDistance   # None | iou | chamferDistance
    losses: "l2,kl" #additional loss names
    lr: 1.0e-3
    criterion: L1
    base_kl_weight: 0
    reconst_weight: 1 #1
    scheduler_step_size: 300
    scheduler_gamma: 0.5
    cycle_iter: 20000
    stop_cycle_count: 1
   #stop_cycle_count: 1
    weight_init: normal    #None | normal | xavier | xavier_uniform | kaiming | orthogonal
    gain: 0.02
    auto_encoder_networks:
      in_channels: 1
      out_channels: 32
      ch_mult: [1, 2, 2,2, 2]
      num_res_blocks: 1
      attn_resolutions: [8]
      dropout: 0.0
      resamp_with_conv: true
      resolution: 64
  
  pvqvae:
    model_filepath: src/models/pvqvae.py
    model_class: PVQVAE
    metrics: iou,chamferDistance   # None | iou | chamferDistance
    losses: "l1,codebook" #additional loss names
    lr: 1.0e-4
    criterion: L1
    scheduler_step_size: 50
    scheduler_gamma: 0.5
    weight_init: normal    #None | normal | xavier | xavier_uniform | kaiming | orthogonal
    gain: 0.02
    embed_dim: 256
    n_embed: 512
    auto_encoder_networks:
      in_channels: 1
      out_channels: 64
      ch_mult: [1, 2, 2, 4]
      num_res_blocks: 1
      attn_resolutions: [8]
      dropout: 0.0
      resamp_with_conv: true
      resolution: 64
  
  decoder_transformer:
    model_filepath: src/models/random_transformer.py
    model_class: RandTransformer
    metrics: iou,chamferDistance   # None | iou | chamferDistance
    losses: None #additional loss names
    lr: 1.0e-4
    criterion: L1
    scheduler_step_size: 30
    scheduler_gamma: 0.9
    weight_init: None
    embed_dim: 768
    n_tokens: 512
    n_head: 12
    n_layers_enc: 12
    d_mlp: 256
    dropout: 0.1
    pvqvae:
      embed_dim: 256
      n_embed: 512
      ckpt_path: logs/pvqVAE/pvqVAE-Train/2024_05_26_02_46_01/checkpoints/epoch-114.ckpt
    p_encoding:
      init_factor: 10
      pos_dim: 3
      zq_dim: 8
      pos_embed_dim: 128
  
  globalPVQVAE:
    model_filepath: src/models/global_pvqvae.py
    model_class: GlobalPVQVAE
    metrics: iou,chamferDistance   # None | iou | chamferDistance
    losses: "l1,codebook" #additional loss names
    lr: 1.0e-4
    criterion: L1
    scheduler_step_size: 50
    scheduler_gamma: 0.5
    weight_init: normal    #None | normal | xavier | xavier_uniform | kaiming | orthogonal
    gain: 0.02
    embed_dim: 256
    n_embed: 512
    auto_encoder_networks:
      in_channels: 1
      out_channels: 64
      ch_mult: [1, 2, 2, 4]
      num_res_blocks: 1
      attn_resolutions: [8]
      dropout: 0.0
      resamp_with_conv: true
      resolution: 64


evaluation:
  ckpt_path: #Path of saved parameters
