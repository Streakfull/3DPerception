{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.util import mkdir,seed_all\n",
    "from omegaconf import OmegaConf\n",
    "from cprint import *\n",
    "from datasets.shape_net.shape_net_vox import ShapeNetVox\n",
    "from models.dummy_classifier import DummyClassifier\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.visualizations import save_voxels\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "%load_ext autoreload\n",
    "%load_ext tensorboard\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Expirement Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs_path = \"./configs/global_configs.yaml\"\n",
    "global_configs = OmegaConf.load(configs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "seed_all(111)\n",
    "training_config = global_configs[\"training\"]\n",
    "today = time.strftime(\"%Y-%m-%d\")\n",
    "cprint.ok(training_config)\n",
    "description = training_config[\"description\"]  # Describe Experiment params here\n",
    "logs_dir = training_config[\"logs_dir\"]\n",
    "mkdir(logs_dir)\n",
    "experiment_dir = f\"{logs_dir}/{training_config['name']}/{training_config['experiment_id']}\"\n",
    "mkdir(experiment_dir)\n",
    "loss_log_title = \"Loss Log \" + today\n",
    "\n",
    "with open(f\"{experiment_dir}/description.txt\", \"w\") as file1:\n",
    "    file1.write(description)\n",
    "\n",
    "with open(f\"{experiment_dir}/global_configs.txt\", \"w\") as file1:\n",
    "    file1.write(str(training_config))\n",
    "\n",
    "with open(f\"{experiment_dir}/loss_log.txt\", \"w\") as file1:\n",
    "    file1.write(loss_log_title)\n",
    "    file1.write(\"\\n\")\n",
    "\n",
    "\n",
    "mkdir(f\"{experiment_dir}/checkpoints\")\n",
    "mkdir(f\"{experiment_dir}/tb\")\n",
    "mkdir(f\"{experiment_dir}/visuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset & Dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change overfit param here & cat here\n",
    "global_dataset_config = global_configs[\"dataset\"]\n",
    "local_dataset_config = global_dataset_config[\"shape_net_vox\"]\n",
    "DataSet = ShapeNetVox\n",
    "dataset = DataSet(global_dataset_config, local_dataset_config)\n",
    "print('length: ', len(dataset))\n",
    "dataset[0]\n",
    "# train_ds, valid_ds, test_ds = torch.utils.data.random_split(\n",
    "#     dataset, [1,1,1])\n",
    "\n",
    "train_ds,valid_ds, test_ds = dataset, dataset, dataset\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_ds,   # Datasets return data one sample at a time; Dataloaders use them and aggregate samples into batches\n",
    "    batch_size=training_config['batch_size'],   # The size of batches is defined here\n",
    "    shuffle=True,    # Shuffling the order of samples is useful during training to prevent that the network learns to depend on the order of the input data\n",
    "    num_workers=6,   # Data is usually loaded in parallel by num_workers\n",
    "    pin_memory=True,  # This is an implementation detail to speed up data uploading to the GPU\n",
    "    # worker_init_fn=train_dataset.worker_init_fn  TODO: Uncomment this line if you are using shapenet_zip on Google Colab\n",
    ")\n",
    "\n",
    "validation_dataloader = torch.utils.data.DataLoader(\n",
    "    valid_ds,   # Datasets return data one sample at a time; Dataloaders use them and aggregate samples into batches\n",
    "    batch_size=training_config['batch_size'],   # The size of batches is defined here\n",
    "    shuffle=True,    # Shuffling the order of samples is useful during training to prevent that the network learns to depend on the order of the input data\n",
    "    num_workers=6,   # Data is usually loaded in parallel by num_workers\n",
    "    pin_memory=True,  # This is an implementation detail to speed up data uploading to the GPU\n",
    "    # worker_init_fn=train_dataset.worker_init_fn  TODO: Uncomment this line if you are using shapenet_zip on Google Colab\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = global_configs[\"model\"][\"dummy_classifier\"]\n",
    "model = DummyClassifier(model_configs)\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available() and training_config['device'].startswith('cuda'):\n",
    "    device = torch.device(training_config['device'])\n",
    "    cprint.ok('Using device:', training_config['device'])\n",
    "else:\n",
    "    cprint.warn('Using CPU')\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "if(training_config[\"load_ckpt\"]):\n",
    "    model.load_ckpt(training_config['ckpt_path'])\n",
    "\n",
    "if(torch.cuda.is_available()):\n",
    "    torch.cuda.mem_get_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_running = 0.\n",
    "best_loss_val = np.inf\n",
    "model.train()\n",
    "start_iteration = training_config[\"start_iteration\"]\n",
    "tb_dir = f\"{experiment_dir}/tb\"\n",
    "writer = SummaryWriter(log_dir=tb_dir)\n",
    "model_checkpoint_path = f\"{experiment_dir}/checkpoints\"\n",
    "loss_log_name = f\"{experiment_dir}/loss_log.txt\"\n",
    "visuals_path = f\"{experiment_dir}/visuals\"\n",
    "last_loss = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, writer):\n",
    "    global best_loss_val\n",
    "    global last_loss\n",
    "    global start_iteration\n",
    "    train_loss_running = 0.\n",
    "    iteration_count = 0\n",
    "    for batch_idx, batch in tqdm(enumerate(train_dataloader)):\n",
    "         iteration = epoch * len(train_dataloader) + batch_idx \n",
    "         if(iteration<= start_iteration):\n",
    "            continue\n",
    "         DataSet.move_batch_to_device(batch, device)\n",
    "         model.step(batch)\n",
    "         metrics = model.get_metrics()\n",
    "         loss = metrics[\"loss\"]\n",
    "         train_loss_running += loss\n",
    "         iteration_count += 1\n",
    "\n",
    "         if iteration % training_config[\"append_loss_every\"] == (training_config[\"append_loss_every\"] - 1) or (epoch==0 and iteration==0):\n",
    "            message = '(epoch: %d, iters: %d, loss: %.6f)' % (epoch, iteration, loss.item())\n",
    "            with open(loss_log_name, \"a\") as log_file:\n",
    "                log_file.write('%s\\n' % message)\n",
    "            print(loss)\n",
    "\n",
    "         if iteration % training_config[\"visualize_every\"] == (training_config[\"visualize_every\"] - 1):\n",
    "            # Do visualizations here\n",
    "            cprint.ok(\"visuals here\")\n",
    "        \n",
    "         if iteration % training_config['print_every'] == (training_config['print_every'] - 1) or (epoch==0 and iteration==0):\n",
    "            avg_train_loss = train_loss_running / iteration_count\n",
    "            cprint.warn(f'[{epoch:03d}/{batch_idx:05d}] train_loss: {avg_train_loss:.6f}')\n",
    "            writer.add_scalar(\"Train/Loss\", avg_train_loss, iteration)\n",
    "            last_loss = avg_train_loss\n",
    "            train_loss_running = 0.\n",
    "            iteration_count = 0\n",
    "        \n",
    "         if iteration % training_config['save_every'] == (training_config['save_every'] - 1):\n",
    "            model.save(model_checkpoint_path, \"latest\")\n",
    "\n",
    "         if iteration % training_config['validate_every'] == (training_config['validate_every'] - 1) or (epoch == 0 and iteration == 0):\n",
    "            cprint.ok(\"Running Validation\")\n",
    "            model.eval()\n",
    "            loss_val = 0.\n",
    "            index_batch = 0\n",
    "            for batch_idx, batch_val in tqdm(enumerate(validation_dataloader)):\n",
    "                DataSet.move_batch_to_device(batch_val, device)\n",
    "                with torch.no_grad():\n",
    "                    model.inference(batch_val)\n",
    "                    metrics = model.get_metrics()\n",
    "                    loss_val += metrics[\"loss\"]\n",
    "                    index_batch += 1\n",
    "            avg_loss_val = loss_val / (index_batch)\n",
    "\n",
    "            #Do visualizations here\n",
    "            if avg_loss_val < best_loss_val:\n",
    "                model.save(model_checkpoint_path, \"best\")\n",
    "                best_loss_val = avg_loss_val\n",
    "            \n",
    "            cprint.warn(f'[{epoch:03d}/{batch_idx:05d}] val_loss: {avg_loss_val:.6f} | best_loss_val: {best_loss_val:.6f}')\n",
    "            writer.add_scalar(\"Validation/Loss\", avg_loss_val, iteration)\n",
    "            writer.add_scalars('Validation/LossComparison',\n",
    "                   { 'Training' : last_loss, 'Validation' : avg_loss_val },\n",
    "                    iteration)\n",
    "            writer.flush()\n",
    "         return last_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = training_config[\"start_epoch\"]\n",
    "for epoch in tqdm(range(training_config['n_epochs'])):\n",
    "    if epoch < start_epoch:\n",
    "        continue\n",
    "    avg_loss = train_one_epoch(epoch, writer)\n",
    "    # if(epoch % config[\"save_every_nepochs\"]==0):\n",
    "    model.save(model_checkpoint_path, epoch)\n",
    "    model.update_lr()\n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
