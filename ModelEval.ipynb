{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6589c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Before: %s (10120527872, 10385358848)\n",
      "\u001b[94mUsing device:\u001b[0m cuda:0\n",
      "\u001b[94m{'name': 'presentationModelComparison', 'description': 'plzWork2', 'experiment_id': 'Dev', 'extra_notes': 'none', 'logs_dir': 'logs', 'is_train': True, 'device': 'cuda:0', 'batch_size': 16, 'num_workers': 20, 'test_size': 0.1, 'n_epochs': 50000, 'append_loss_every': 50, 'print_every': 10, 'validate_every': 1480, 'save_every': 1480, 'save_every_nepochs': 5, 'start_epoch': 0, 'start_iteration': 0, 'visualize_every': 200, 'apply_metrics_every': 1480, 'load_ckpt': True, 'ckpt_path': 'logs/GlobalPVQVAE/FullTrain/2024_06_03_12_37_19/checkpoints/epoch-latest.ckpt', 'use_scheduler': True, 'apply_metrics_batch_count': 5}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m- Creating new directory logs/presentationModelComparison/Dev/2024_06_05_22_41_45\u001b[0m\n",
      "\u001b[93m- Creating new directory logs/presentationModelComparison/Dev/2024_06_05_22_41_45/checkpoints\u001b[0m\n",
      "\u001b[93m- Creating new directory logs/presentationModelComparison/Dev/2024_06_05_22_41_45/tb\u001b[0m\n",
      "\u001b[93m- Creating new directory logs/presentationModelComparison/Dev/2024_06_05_22_41_45/visuals\u001b[0m\n",
      "\u001b[93m- Creating new directory logs/presentationModelComparison/Dev/2024_06_05_22_41_45/modelsummary\u001b[0m\n",
      "/home/youssef/.cache/pypoetry/virtualenvs/vqgan_scene_reconstruction-cT5po-tB-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "[*] Enc has Attn at i_level, i_block: 3, 0\n",
      "Decoding of shape (1, 64, 8, 8, 8) = 32768 dimensions.\n",
      "[*] Dec has Attn at i_level, i_block: 3, 0\n",
      "\u001b[94mUsing device:\u001b[0m cuda:0\n",
      "\u001b[94mInitializing model weights with normal initialization\u001b[0m\n",
      "Model loaded from logs/GlobalPVQVAE/FullTrain/2024_06_03_12_37_19/checkpoints/epoch-latest.ckpt\n",
      "Model size: 99.591MB\n",
      "Total_params: 26.1M\n",
      "Dataset length:  6579\n",
      "Memory After: %s (6695878656, 10385358848)\n"
     ]
    }
   ],
   "source": [
    "from src.training.ModelTrainer import ModelTrainer\n",
    "from src.datasets.shape_net.shape_net_v3_sdf import ShapeNetV3SDF\n",
    "from src.utils.util import seed_all\n",
    "from src.utils.visualizations import visualize_sdf_as_mesh\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "%load_ext autoreload\n",
    "%load_ext tensorboard\n",
    "%autoreload 2\n",
    "seed_all(111)\n",
    "mem = torch.cuda.mem_get_info()\n",
    "print(\"Memory Before: %s\", mem)\n",
    "trainer = ModelTrainer(dataset_type=ShapeNetV3SDF,\n",
    "                       options={\"tdm_notebook\": True})\n",
    "\n",
    "dataset = trainer.data_loader_handler.dataset\n",
    "print(\"Dataset length: \", len(dataset))\n",
    "mem = torch.cuda.mem_get_info()\n",
    "print(\"Memory After: %s\", mem)\n",
    "model = trainer.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0db48202",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youssef/.cache/pypoetry/virtualenvs/vqgan_scene_reconstruction-cT5po-tB-py3.10/lib/python3.10/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 20 worker processes in total. Our suggested max number of worker in current system is 16, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e24afcb51e4ec4b123abefcd32ce04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_0.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_1.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_2.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_3.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_4.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_5.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_6.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_7.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_8.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_9.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_10.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_11.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_12.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_13.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_14.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_15.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_16.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_17.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_18.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_19.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_20.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_21.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_22.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_23.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_24.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_25.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_26.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_27.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_28.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_29.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_30.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_31.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_32.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_33.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_34.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_35.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_36.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_37.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_38.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_39.png saved\n",
      "./src/testVisuals/autoEncoder//reconst/epoch_0_iter_40.png saved\n"
     ]
    }
   ],
   "source": [
    "from src.training.SDFVisualizer import SDFVisualizer\n",
    "from src.metrics.pytorch_3d_chamfer_dist import Pytorch3DChamferDistance\n",
    "from src.metrics.signed_iou import SignedIou\n",
    "from src.metrics.pytorch_3d_chamfer_dist import Pytorch3DChamferDistance\n",
    "from src.metrics.signed_iou import SignedIou\n",
    "chm = Pytorch3DChamferDistance()\n",
    "iou = SignedIou()\n",
    "path = \"./src/testVisuals/autoEncoder/\"\n",
    "data_loader = trainer.data_loader_handler.validation_dataloader\n",
    "with torch.no_grad():\n",
    "    chamferDistTotal = 0\n",
    "    iouTotal = 0\n",
    "    i = 0\n",
    "    for index, batch in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        ShapeNetV3SDF.move_batch_to_device(batch, \"cuda:0\")\n",
    "        sdfs = batch['sdf']\n",
    "        pred = model.inference(sdfs)\n",
    "        visualizer = SDFVisualizer(\"cuda:0\",path,\"reconst\", 0, index)\n",
    "        visualizer.visualize(sdfs)\n",
    "        chamferDistTotal += chm.calc_batch(pred,sdfs)\n",
    "        iouTotal += iou.calc_batch(pred, sdfs)\n",
    "        i+=1\n",
    "chamferDistTotal =  chamferDistTotal/(i)\n",
    "iouTotal = iouTotal/(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1422c145",
   "metadata": {},
   "outputs": [],
   "source": [
    "iouTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9374795",
   "metadata": {},
   "outputs": [],
   "source": [
    "chamferDistTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620ccd3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
