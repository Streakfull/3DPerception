{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6589c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "Memory Before: %s (1780154368, 10385358848)\n",
      "\u001b[94mUsing device:\u001b[0m cuda:0\n",
      "\u001b[94m{'name': 'globalPVQVAEVGG', 'description': 'plz', 'experiment_id': 'Vis', 'extra_notes': 'none', 'logs_dir': 'logs', 'is_train': True, 'device': 'cuda:0', 'batch_size': 16, 'num_workers': 16, 'test_size': 0.1, 'n_epochs': 50000, 'append_loss_every': 250, 'print_every': 500, 'validate_every': 1973, 'save_every': 1973, 'save_every_nepochs': 2, 'start_epoch': 0, 'start_iteration': 0, 'visualize_every': 1000, 'apply_metrics_every': 1973, 'load_ckpt': True, 'ckpt_path': 'logs/globalPVQVAEVGG/fullTrain/2024_07_03_12_16_57/checkpoints/epoch-latest.ckpt', 'use_scheduler': True, 'apply_metrics_batch_count': 5}\u001b[0m\n",
      "[*] Enc has Attn at i_level, i_block: 3, 0\n",
      "Decoding of shape (1, 256, 8, 8, 8) = 131072 dimensions.\n",
      "[*] Dec has Attn at i_level, i_block: 3, 0\n",
      "\u001b[94mUsing device:\u001b[0m cuda:0\n",
      "\u001b[94mInitializing model weights with normal initialization\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93m- Creating new directory logs/globalPVQVAEVGG/Vis/2024_07_04_10_40_22\u001b[0m\n",
      "\u001b[93m- Creating new directory logs/globalPVQVAEVGG/Vis/2024_07_04_10_40_22/checkpoints\u001b[0m\n",
      "\u001b[93m- Creating new directory logs/globalPVQVAEVGG/Vis/2024_07_04_10_40_22/tb\u001b[0m\n",
      "\u001b[93m- Creating new directory logs/globalPVQVAEVGG/Vis/2024_07_04_10_40_22/visuals\u001b[0m\n",
      "\u001b[93m- Creating new directory logs/globalPVQVAEVGG/Vis/2024_07_04_10_40_22/modelsummary\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from logs/globalPVQVAEVGG/fullTrain/2024_07_03_12_16_57/checkpoints/epoch-latest.ckpt\n",
      "Model size: 110.092MB\n",
      "Total_params: 28.9M\n",
      "Dataset length:  6579\n",
      "Memory After: %s (1780154368, 10385358848)\n"
     ]
    }
   ],
   "source": [
    "from src.training.ModelTrainer import ModelTrainer\n",
    "from src.datasets.shape_net.shape_net_v3_sdf import ShapeNetV3SDF\n",
    "from src.utils.util import seed_all\n",
    "from src.utils.visualizations import visualize_sdf_as_mesh\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "%load_ext autoreload\n",
    "%load_ext tensorboard\n",
    "%autoreload 2\n",
    "seed_all(111)\n",
    "mem = torch.cuda.mem_get_info()\n",
    "print(\"Memory Before: %s\", mem)\n",
    "trainer = ModelTrainer(dataset_type=ShapeNetV3SDF,\n",
    "                       options={\"tdm_notebook\": True})\n",
    "\n",
    "dataset = trainer.data_loader_handler.dataset\n",
    "print(\"Dataset length: \", len(dataset))\n",
    "mem = torch.cuda.mem_get_info()\n",
    "print(\"Memory After: %s\", mem)\n",
    "model = trainer.model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0db48202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2acf2355b614c6f81d9f77b0f19299d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_0.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_1.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_2.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_3.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_4.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_5.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_6.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_7.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_8.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_9.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_10.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_11.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_12.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_13.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_14.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_15.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_16.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_17.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_18.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_19.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_20.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_21.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_22.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_23.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_24.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_25.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_26.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_27.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_28.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_29.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_30.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_31.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_32.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_33.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_34.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_35.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_36.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_37.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_38.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_39.png saved\n",
      "./src/testVisuals/vggPvqvaeGlobal/normal/epoch_0_iter_40.png saved\n"
     ]
    }
   ],
   "source": [
    "from src.training.SDFVisualizer import SDFVisualizer\n",
    "from src.metrics.pytorch_3d_chamfer_dist import Pytorch3DChamferDistance\n",
    "from src.metrics.signed_iou import SignedIou\n",
    "from src.metrics.pytorch_3d_chamfer_dist import Pytorch3DChamferDistance\n",
    "from src.metrics.signed_iou import SignedIou\n",
    "chm = Pytorch3DChamferDistance()\n",
    "iou = SignedIou()\n",
    "path = \"./src/testVisuals/vggPvqvaeGlobal\"\n",
    "data_loader = trainer.data_loader_handler.validation_dataloader\n",
    "with torch.no_grad():\n",
    "    chamferDistTotal = 0\n",
    "    iouTotal = 0\n",
    "    i = 0\n",
    "    for index, batch in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "        ShapeNetV3SDF.move_batch_to_device(batch, \"cuda:0\")\n",
    "        sdfs = batch['sdf']\n",
    "        pred = model.inference(sdfs)\n",
    "        visualizer = SDFVisualizer(\"cuda:0\",path,\"normal\", 0, index)\n",
    "        visualizer.visualize(pred)\n",
    "        chamferDistTotal += chm.calc_batch(pred,sdfs)\n",
    "        iouTotal += iou.calc_batch(pred, sdfs)\n",
    "        i+=1\n",
    "chamferDistTotal =  chamferDistTotal/(i)\n",
    "iouTotal = iouTotal/(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1422c145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7846, device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iouTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9374795",
   "metadata": {},
   "outputs": [],
   "source": [
    "chamferDistTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620ccd3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
